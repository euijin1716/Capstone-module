#%%
# 1. ë¼ì´ë¸ŒëŸ¬ë¦¬ ì„í¬íŠ¸ ë° API í‚¤ ì„¤ì •
###############################################################################################################################################################################

import os
import google.generativeai as genai
import json
import argparse
import time
import traceback
from tenacity import retry, stop_after_attempt, wait_exponential, retry_if_exception_type
from google.api_core import exceptions

# Import prompts from external file
import prompts

# Configuration
MODEL_NAME = "models/gemini-2.5-pro"
BUFFER_SIZE = 10             # ì•ë’¤ ë¬¸ë§¥ í¬í•¨ ê°œìˆ˜
WAIT_SECONDS = 60            # API í˜¸ì¶œ ê°„ ëŒ€ê¸° ì‹œê°„ (ì´ˆ)

# ==============================================================================
# 1. API í˜¸ì¶œ í—¬í¼ í•¨ìˆ˜ (Retry ì ìš©)
# ==============================================================================
@retry(
    retry=retry_if_exception_type((
        exceptions.ResourceExhausted, 
        exceptions.ServiceUnavailable, 
        exceptions.GoogleAPICallError,
        exceptions.InternalServerError
    )),
    stop=stop_after_attempt(5),
    wait=wait_exponential(multiplier=1, min=4, max=60)
)
def generate_content_with_retry(model, prompt):
    """
    Gemini API í˜¸ì¶œì„ ìˆ˜í–‰í•˜ë©°, ì‹¤íŒ¨ ì‹œ ì§€ìˆ˜ ë°±ì˜¤í”„ë¡œ ì¬ì‹œë„í•©ë‹ˆë‹¤.
    """
    return model.generate_content(prompt)

# ==============================================================================
# 2. ID ê¸°ë°˜ í…ìŠ¤íŠ¸ ì¶”ì¶œ í•¨ìˆ˜ (Buffer ì ìš©)
# ==============================================================================
def get_transcript_segment(all_utterances, start_id, end_id, buffer=5):
    """
    ì „ì²´ ë°œí™” ëª©ë¡ì—ì„œ íŠ¹ì • ID êµ¬ê°„ì˜ í…ìŠ¤íŠ¸ë§Œ ì¶”ì¶œí•©ë‹ˆë‹¤.
    ì•ë’¤ë¡œ bufferë§Œí¼ì˜ ë°œí™”ë¥¼ ë” í¬í•¨í•˜ì—¬ ë¬¸ë§¥ì„ í™•ë³´í•©ë‹ˆë‹¤.
    """
    start_idx = -1
    end_idx = -1
    
    # ì¸ë±ìŠ¤ ì°¾ê¸° (ë¬¸ìì—´/ì •ìˆ˜ í˜¸í™˜ ìœ„í•´ str ë³€í™˜ ë¹„êµ)
    for i, u in enumerate(all_utterances):
        if str(u.get('id')) == str(start_id):
            start_idx = i
        if str(u.get('id')) == str(end_id):
            end_idx = i
            if start_idx != -1: break 
            
    if start_idx == -1 or end_idx == -1:
        return "" # IDë¥¼ ëª» ì°¾ì€ ê²½ìš° ë¹ˆ ë¬¸ìì—´ ë°˜í™˜

    # ë²„í¼ ì ìš© (ë¦¬ìŠ¤íŠ¸ ë²”ìœ„ ë³´í˜¸)
    real_start = max(0, start_idx - buffer)
    real_end = min(len(all_utterances), end_idx + 1 + buffer)
    
    segment_lines = []
    for i in range(real_start, real_end):
        u = all_utterances[i]
        u_id = u.get('id')
        name = u.get('name', 'Unknown')
        content = u.get('content', '')
        segment_lines.append(f"[ID: {u_id}] {name}: {content}")
        
    return "\n".join(segment_lines)


# ==============================================================================
# 3. êµ¬ì¡° ë¶„ì„ í•¨ìˆ˜ (Step 2 & 3)
# ==============================================================================
def analyze_structure(file_id):
    print(f"\n{'='*80}")
    print(f"ğŸ—ï¸ [Step 1] êµ¬ì¡° ë¶„ì„ ì‹œì‘: {file_id}")
    print(f"{'='*80}\n")
    
    json_file_path = f"{file_id}_cleansed.json"
    
    try:
        # 1. JSON íŒŒì¼ ì§ì ‘ ì½ê¸°
        with open(json_file_path, 'r', encoding='utf-8') as f:
            meeting_log_data = json.load(f)
        
        # --- í”„ë¡¬í”„íŠ¸ì— í¬í•¨í•  ë‚´ìš© ê°€ê³µ ---
        metadata_str = json.dumps(meeting_log_data.get('metadata', {}), ensure_ascii=False, indent=2)
        speakers_str = json.dumps(meeting_log_data.get('speakers', []), ensure_ascii=False, indent=2)
        
        speaker_map = {speaker['id']: speaker.get('name', f"P{i:02d}") for i, speaker in enumerate(meeting_log_data.get('speakers', []))}
        conversation_text_lines = []
        
        for utterance in meeting_log_data.get('utterances', []):
            u_id = utterance.get('id')
            speaker_id = utterance.get('name') 
            message = utterance.get('content')
            
            if speaker_id and message and u_id:
                speaker_label = speaker_map.get(speaker_id, speaker_id)
                conversation_text_lines.append(f"[ID: {u_id}] {speaker_label}: {message}")
                
        conversation_text = "\n".join(conversation_text_lines)
        
        prompt_input_text = f"""# Metadata
{metadata_str}

# Speakers
{speakers_str}

# Conversation
{conversation_text}
"""
        print(f"'{json_file_path}' íŒŒì¼ ë‚´ìš© ë¡œë“œ ë° í”„ë¡¬í”„íŠ¸ìš© ë°ì´í„° ê°€ê³µ ì™„ë£Œ.")

        # --- êµ¬ì¡° ë° êµ¬ê°„ ì¶”ì¶œìš© í”„ë¡¬í”„íŠ¸ ---
        # prompts.pyì—ì„œ í…œí”Œë¦¿ ê°€ì ¸ì˜¤ê¸°
        prompt_text_template = prompts.STRUCTURE_PROMPT.format(input_data=prompt_input_text)

        # ëª¨ë¸ ì´ˆê¸°í™”
        model = genai.GenerativeModel(MODEL_NAME)
        print(f"Gemini ëª¨ë¸ ì´ˆê¸°í™” ì„±ê³µ. (ëª¨ë¸: {MODEL_NAME})")
        
        # í”„ë¡¬í”„íŠ¸ ì „ë‹¬ (Retry ì ìš©)
        print("---ì „ì†¡ë  í”„ë¡¬í”„íŠ¸---")
        response = generate_content_with_retry(model, prompt_text_template)
        
        print("\n--- Gemini API ì‘ë‹µ ---")
        
        # JSON íŒŒì‹±
        json_string = response.text.strip().replace("```json", "").replace("```", "").strip()
        parsed_json = json.loads(json_string)
        print(json.dumps(parsed_json, indent=2, ensure_ascii=False))
        
        # Skeleton ì €ì¥
        if 'skeleton' not in meeting_log_data:
            meeting_log_data['skeleton'] = {}
            
        meeting_log_data['skeleton']['main_topic'] = parsed_json.get('main_topic', '')
        meeting_log_data['skeleton']['domain'] = parsed_json.get('domain', '')
        meeting_log_data['skeleton']['topics'] = parsed_json.get('topics', [])
        
        output_json_file_path = f"{file_id}_step1.json" 
        with open(output_json_file_path, 'w', encoding='utf-8') as f:
            json.dump(meeting_log_data, f, ensure_ascii=False, indent=4)
            
        print(f"  íŒŒì¼ ì €ì¥ ì™„ë£Œ: '{output_json_file_path}'")
        return True

    except FileNotFoundError:
        print(f"ì˜¤ë¥˜: '{json_file_path}' íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        return False
    except Exception as e:
        print(f"êµ¬ì¡° ë¶„ì„ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
        traceback.print_exc()
        return False


# ==============================================================================
# 4. ìƒì„¸ ë¶„ì„ ë° í†µí•© í•¨ìˆ˜ (Step 4 & 5)
# ==============================================================================
def analyze_details_and_consolidate(file_id):
    print(f"\n{'='*80}")
    print(f"ğŸ” [Step 2] ìƒì„¸ ë¶„ì„ ë° í†µí•© ì‹œì‘: {file_id}")
    print(f"{'='*80}\n")
    
    step1_file_path = f"{file_id}_step1.json"
    
    try:
        with open(step1_file_path, 'r', encoding='utf-8') as f:
            meeting_log_data = json.load(f)
            
        topics_list = meeting_log_data.get('skeleton', {}).get('topics', [])
        all_utterances = meeting_log_data.get('utterances', [])
        final_topics = []
        
        if not topics_list:
            print("âš ï¸ ì²˜ë¦¬í•  í† í”½ì´ ì—†ìŠµë‹ˆë‹¤. Step 1 ê²°ê³¼ë¥¼ í™•ì¸í•˜ì„¸ìš”.")
            return False
            
        total_topics = len(topics_list)
        print(f"âœ… ì´ {total_topics}ê°œì˜ í† í”½ì„ ë¶„ì„í•©ë‹ˆë‹¤. (Buffer: Â±{BUFFER_SIZE}, ëŒ€ê¸°ì‹œê°„: {WAIT_SECONDS}ì´ˆ)\n")
        
        model = genai.GenerativeModel(MODEL_NAME)
        
        # --- ìƒì„¸ ë¶„ì„ Loop ---
        for index, topic_item in enumerate(topics_list):
            topic_item['sub_topic_id'] = str(index + 1)
            sub_topic = topic_item.get('sub_topic', 'ì œëª© ì—†ìŒ')
            topic_type = topic_item.get('type', 'unknown')
            start_id = topic_item.get('start_id')
            end_id = topic_item.get('end_id')
            
            print(f"ğŸ”„ [Topic {index+1}/{total_topics}] ì²˜ë¦¬ ì¤‘...")
            print(f"   - ì£¼ì œ: {sub_topic}")
            print(f"   - ìœ í˜•: {topic_type}")
            print(f"   - êµ¬ê°„: ID {start_id} ~ {end_id}")
            
            segment_text = get_transcript_segment(all_utterances, start_id, end_id, buffer=BUFFER_SIZE)
            
            if not segment_text:
                print("   -> ê²½ê³ : í…ìŠ¤íŠ¸ ì¶”ì¶œ ì‹¤íŒ¨ (ID í™•ì¸ í•„ìš”). Skip.")
                topic_item['error'] = "Text extraction failed"
                final_topics.append(topic_item)
                continue

            # prompts.pyì—ì„œ í…œí”Œë¦¿ ê°€ì ¸ì˜¤ê¸°
            type_instruction = prompts.TYPE_PROMPTS.get(topic_type, prompts.DEFAULT_PROMPT)
            
            step2_prompt = f"""
# í˜ë¥´ì†Œë‚˜
ë‹¹ì‹ ì€ íšŒì˜ë¡ì˜ íŠ¹ì • ì„¸ê·¸ë¨¼íŠ¸ë¥¼ ì •ë°€ ë¶„ì„í•˜ëŠ” ì „ë¬¸ê°€ì…ë‹ˆë‹¤.

# ì‘ì—… ê°œìš”
* **ë¶„ì„ ëŒ€ìƒ ì£¼ì œ**: '{sub_topic}'
* **í•µì‹¬ ë…¼ì˜ êµ¬ê°„**: ID {start_id}ë²ˆ ~ {end_id}ë²ˆ ë°œí™”
* **ì°¸ê³  ë¬¸ë§¥(Buffer)**: í•µì‹¬ êµ¬ê°„ì˜ ì•ë’¤ë¡œ ê°ê° {BUFFER_SIZE}ê°œì˜ ë°œí™”ê°€ ë¬¸ë§¥ íŒŒì•…ì„ ìœ„í•´ ì¶”ê°€ë˜ì—ˆìŠµë‹ˆë‹¤.

# ì‘ì—… ì§€ì‹œ
ì œê³µëœ [ëŒ€í™” ë‚´ìš©]ì„ ì½ê³ , **í•µì‹¬ ë…¼ì˜ êµ¬ê°„**ì„ ì¤‘ì‹¬ìœ¼ë¡œ ë‹¤ìŒ ë‚´ìš©ì„ ì¶”ì¶œí•˜ì„¸ìš”.

1. **details (ìƒì„¸ ë‚´ìš©)**: ì•„ë˜ [ì‘ì„± ì§€ì¹¨]ì— ì •ì˜ëœ êµ¬ì¡°ëŒ€ë¡œ ì‘ì„±í•˜ì„¸ìš”.
2. **segment_decisions (ê²°ì • ì‚¬í•­)**: ì´ êµ¬ê°„ì—ì„œ í™•ì •ëœ í•©ì˜ë‚˜ ê²°ì • ì‚¬í•­ì´ ìˆë‹¤ë©´ ëª…í™•í•œ ë¬¸ì¥ìœ¼ë¡œ ì¶”ì¶œí•˜ì„¸ìš”. (ì—†ìœ¼ë©´ ë¹ˆ ë¦¬ìŠ¤íŠ¸)
3. **segment_action_items (ì‹¤í–‰ í•­ëª©)**: êµ¬ì²´ì ì¸ í•  ì¼(Task), ë‹´ë‹¹ì(Assignee), ê¸°í•œ(Due Date)ì„ ì¶”ì¶œí•˜ì„¸ìš”. (ì—†ìœ¼ë©´ ë¹ˆ ë¦¬ìŠ¤íŠ¸)

# ì‘ì„± ì§€ì¹¨ (JSON Schema & Guide)
{type_instruction}

# í•„ìˆ˜ ì¶œë ¥ í˜•ì‹ (JSON Only)
ë°˜ë“œì‹œ ì•„ë˜ í¬ë§·ìœ¼ë¡œ ì‘ë‹µí•˜ì„¸ìš”. ë§ˆí¬ë‹¤ìš´(```json)ì´ë‚˜ ì¶”ê°€ ì„¤ëª…ì€ ì œì™¸í•˜ì„¸ìš”.
{{
  "short_summary": "ì´ ì£¼ì œì— ëŒ€í•œ 1~2ë¬¸ì¥ ìš”ì•½",
  "details": {{ ...ìœ„ ì‘ì„± ì§€ì¹¨ì˜ êµ¬ì¡°... }},
  "segment_decisions": [
    "ê²°ì •ëœ ì‚¬í•­ 1",
    "ê²°ì •ëœ ì‚¬í•­ 2"
  ],
  "segment_action_items": [
    {{
      "task": "êµ¬ì²´ì ì¸ ì‘ì—… ë‚´ìš©",
      "assignee": "ë‹´ë‹¹ì (ë˜ëŠ” 'ë¯¸ì •')",
      "due_date": "ë§ˆê°ê¸°í•œ (ë˜ëŠ” 'ë¯¸ì •')"
    }}
  ]
}}

# ëŒ€í™” ë‚´ìš©
{segment_text}
"""
            try:
                print("   -> API í˜¸ì¶œ ì¤‘...")
                # Retry ì ìš©ëœ í•¨ìˆ˜ í˜¸ì¶œ
                response = generate_content_with_retry(model, step2_prompt)
                
                json_string = response.text.strip().replace("```json", "").replace("```", "").strip()
                parsed_response = json.loads(json_string)
                
                topic_item.update(parsed_response)
                print("   -> ë¶„ì„ ë° ë³‘í•© ì™„ë£Œ")
            except Exception as e:
                print(f"   -> API í˜¸ì¶œ/íŒŒì‹± ì˜¤ë¥˜: {e}")
                topic_item['error'] = str(e)
            
            final_topics.append(topic_item)

            if index < total_topics - 1:
                print(f"   -> API ì œí•œ ì¤€ìˆ˜ë¥¼ ìœ„í•´ {WAIT_SECONDS}ì´ˆ ëŒ€ê¸°í•©ë‹ˆë‹¤...")
                time.sleep(WAIT_SECONDS)
        
        # Step 2 ê²°ê³¼ ì €ì¥
        meeting_log_data['skeleton']['topics'] = final_topics
        output_file_path = f"{file_id}_step2.json"
        with open(output_file_path, 'w', encoding='utf-8') as f:
            json.dump(meeting_log_data, f, ensure_ascii=False, indent=2)
        print(f"\n Step 2 ì™„ë£Œ! ê²°ê³¼ê°€ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤: {output_file_path}")
        
        # --- ìµœì¢… í†µí•© (Consolidation) ---
        print(f"âœ… ë¶„ì„ëœ í† í”½ {len(final_topics)}ê°œë¥¼ ë°”íƒ•ìœ¼ë¡œ ìµœì¢… ìš”ì•½ì„ ì‹œì‘í•©ë‹ˆë‹¤.")
        
        topics_json_str = json.dumps(final_topics, ensure_ascii=False, indent=2)
        # prompts.pyì—ì„œ í…œí”Œë¦¿ ê°€ì ¸ì˜¤ê¸°
        final_prompt = prompts.CONSOLIDATION_PROMPT.format(topics_json=topics_json_str)
        
        print("ğŸš€ Gemini API í˜¸ì¶œ ì¤‘... (Final Consolidation)")
        # Retry ì ìš©ëœ í•¨ìˆ˜ í˜¸ì¶œ
        response = generate_content_with_retry(model, final_prompt)
        
        json_string = response.text.strip().replace("```json", "").replace("```", "").strip()
        parsed_result = json.loads(json_string)
        
        ordered_summary = {}
        ordered_summary['main_topic'] = meeting_log_data['skeleton'].get('main_topic', '')
        ordered_summary['domain'] = meeting_log_data['skeleton'].get('domain', '')
        ordered_summary['summary'] = parsed_result.get('summary', '')
        ordered_summary['decisions'] = parsed_result.get('decisions', [])
        ordered_summary['action_items'] = parsed_result.get('action_items', [])
        ordered_summary['topics'] = final_topics
        
        final_output_data = {
            "metadata": meeting_log_data.get('metadata', {}),
            "final_summary": ordered_summary,
            "speakers": meeting_log_data.get('speakers', []),
            "utterances": meeting_log_data.get('utterances', [])
        }
        
        final_output_path = f"{file_id}_final.json"
        with open(final_output_path, 'w', encoding='utf-8') as f:
            json.dump(final_output_data, f, ensure_ascii=False, indent=2)
            
        print(f"\nğŸ‰ [ìµœì¢… ì™„ë£Œ] íšŒì˜ë¡ ìƒì„±ì´ ëë‚¬ìŠµë‹ˆë‹¤!")
        print(f"ğŸ’¾ íŒŒì¼ ì €ì¥ ê²½ë¡œ: {final_output_path}")
        return True

    except FileNotFoundError:
        print(f"ì˜¤ë¥˜: '{step1_file_path}' íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. Step 1ì„ ë¨¼ì € ì‹¤í–‰í•˜ì„¸ìš”.")
        return False
    except Exception as e:
        print(f"ìƒì„¸ ë¶„ì„ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
        traceback.print_exc()
        return False


if __name__ == "__main__":
    # API í‚¤ ì„¤ì •
    try:
        api_key = os.getenv("GEMINI_API_KEY")
        if api_key is None:
            raise ValueError("GEMINI_API_KEY í™˜ê²½ ë³€ìˆ˜ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
        genai.configure(api_key=api_key)
        print("Gemini API í‚¤ ì„¤ì • ì™„ë£Œ.")
    except Exception as e:
        print(f"API í‚¤ ì„¤ì • ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
        exit(1)

    # Argument Parsing
    parser = argparse.ArgumentParser(description="Gemini API Test Script")
    parser.add_argument("--file_ids", nargs='+', required=True, help="Target File IDs (space separated)")
    parser.add_argument("--mode", choices=['all', 'structure', 'details'], default='all', help="Execution mode: 'all' (default), 'structure' (Step 1 only), 'details' (Step 2 only)")
    args, _ = parser.parse_known_args()
    
    target_file_ids = args.file_ids
    mode = args.mode
    
    print(f"ì´ {len(target_file_ids)}ê°œì˜ íŒŒì¼ì„ ì²˜ë¦¬í•©ë‹ˆë‹¤: {target_file_ids}")
    print(f"ì‹¤í–‰ ëª¨ë“œ: {mode}")
    
    for file_id in target_file_ids:
        # Mode: structure (Step 1 only)
        if mode == 'structure':
            analyze_structure(file_id)
            
        # Mode: details (Step 2 only - requires previous step)
        elif mode == 'details':
            analyze_details_and_consolidate(file_id)
            
        # Mode: all (Step 1 -> Step 2)
        else:
            success_step1 = analyze_structure(file_id)
            if success_step1:
                analyze_details_and_consolidate(file_id)
            else:
                print(f"â›” {file_id}: êµ¬ì¡° ë¶„ì„ ì‹¤íŒ¨ë¡œ ì¸í•´ ìƒì„¸ ë¶„ì„ì„ ê±´ë„ˆëœë‹ˆë‹¤.")
